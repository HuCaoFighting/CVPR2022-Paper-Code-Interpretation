* 推荐阅读：<br>
  * [ICCV2021/2019/2017 论文/代码/解读/直播合集](https://github.com/extreme-assistant/ICCV2021-Paper-Code-Interpretation)
  * [2020-2021年计算机视觉综述论文汇总](https://github.com/extreme-assistant/survey-computer-vision)
  * [国内外优秀的计算机视觉团队汇总](https://github.com/extreme-assistant/Awesome-CV-Team)

------

# CVPR2023最新信息及论文下载（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）

官网链接：https://cvpr.thecvf.com/Conferences/2023<br>
论文接收公布时间：2023年2月28日<br>

相关问题：[如何评价 CVPR 2023 的论文接收结果？](https://www.zhihu.com/question/585474435)<br>
相关报道：[CVPR 2023 接收结果出炉！录用2360篇，接收数量上升12%](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247637344&idx=1&sn=62f70870c3f76e6b5a401373986a6ee5&chksm=ec123499db65bd8ffc8987ec1f61b1389e666ed32772149e7c7e76923e2f427ef57e55b57d72&token=1890936456&lang=zh_CN#rd)


>update: <br>
>2023/2/28 [更新13篇](https://www.cvmart.net/community/detail/7212)<br>
>2023/3/02 [更新54篇](https://www.cvmart.net/community/detail/7388)<br>

<br><br>

# 目录

[1. CVPR2023 接受论文/代码分方向汇总（更新中）](#1)<br>
[2. CVPR2023 spotlight（更新中）](#2)<br>
[3. CVPR2023 论文解读汇总（更新中）](#3)<br>
[4. CVPR2023 极市论文分享](#4)<br>
[5. To do list](#5)<br>

<br>

<a name="1"/> 

# 1.CVPR2023接受论文/代码分方向整理(持续更新)


## 分类目录：

### [1. 检测](#detection)

* [2D目标检测(2D Object Detection)](#IOD)
* [视频目标检测(Video Object Detection)](#VOD)
* [3D目标检测(3D Object Detection)](#3DOD)
* [人物交互检测(HOI Detection)](#HOI)
* [伪装目标检测(Camouflaged Object Detection)](#COD)
* [旋转目标检测(Rotation Object Detection)](#ROD)
* [显著性目标检测(Saliency Object Detection)](#SOD)
* [关键点检测(Keypoint Detection)](#KeypointDetection)
* [车道线检测(Lane Detection)](#LaneDetection)
* [边缘检测(Edge Detection)](#EdgeDetection)
* [消失点检测(Vanishing Point Detection)](#VPD)
* [异常检测(Anomaly Detection)](#AnomalyDetection)

### [2. 分割(Segmentation)](#Segmentation)

* [图像分割(Image Segmentation)](#ImageSegmentation)
* [全景分割(Panoptic Segmentation)](#PanopticSegmentation)
* [语义分割(Semantic Segmentation)](#SemanticSegmentation)
* [实例分割(Instance Segmentation)](#InstanceSegmentation)
* [超像素(Superpixel)](#Superpixel)
* [视频目标分割(Video Object Segmentation)](#VOS)
* [抠图(Matting)](#Matting)
* [密集预测(Dense Prediction)](#DensePrediction)

### [3. 图像处理(Image Processing)](#ImageProcessing)

* [超分辨率(Super Resolution)](#SuperResolution)
* [图像复原/图像增强/图像重建(Image Restoration/Image Reconstruction)](#ImageRestoration)
* [图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)](#ISR)
* [图像去噪/去模糊/去雨去雾(Image Denoising)](#ImageDenoising)
* [图像编辑/图像修复(Image Edit/Image Inpainting)](#ImageEdit)
* [图像翻译(Image Translation)](#ImageTranslation)
* [图像质量评估(Image Quality Assessment)](#IQA)
* [风格迁移(Style Transfer)](#StyleTransfer)

### [4. 视频处理(Video Processing)](#VideoProcessing)

* [视频编辑(Video Editing)](#VideoEditing)
* [视频生成/视频合成(Video Generation/Video Synthesis)](#VideoGeneration)
* [视频超分(Video Super-Resolution)](#VideoSR)

### [5. 估计(Estimation)](#Estimation)

* [光流/运动估计(Flow/Motion Estimation)](#Flow/Pose/MotionEstimation)
* [深度估计(Depth Estimation)](#DepthEstimation)
* [人体解析/人体姿态估计(Human Parsing/Human Pose Estimation)](#HumanPoseEstimation)
* [手势估计(Gesture Estimation)](#GestureEstimation)

### [6. 图像&视频检索/(Image&Video Retrieval/Video Understanding)](#ImageRetrieval)

* [行为识别/行为识别/动作识别/检测/分割(Action/Activity Recognition)](#ActionRecognition)
* [行人重识别/检测(Re-Identification/Detection)](#Re-Identification)
* [图像/视频字幕(Image/Video Caption)](#VideoCaption)

### [7. 人脸(Face)](#Face)

* [人脸识别/检测(Facial Recognition/Detection)](#FacialRecognition)
* [人脸生成/合成/重建/编辑(Face Generation/Face Synthesis/Face Reconstruction/Face Editing)](#FaceSynthesis)
* [人脸伪造/反欺骗(Face Forgery/Face Anti-Spoofing)](#FaceAnti-Spoofing)

### [8. 三维视觉(3D Vision)](#3DVision)

* [点云(Point Cloud)](#3DPC)
* [三维重建(3D Reconstruction)](#3DReconstruction)
* [场景重建/视图合成/新视角合成(Novel View Synthesis)](#NeRF)

### [9. 目标跟踪(Object Tracking)](#ObjectTracking)

### [10. 医学影像(Medical Imaging)](#MedicalImaging)

### [11. 文本检测/识别/理解(Text Detection/Recognition/Understanding)](#TDR)

### [12. 遥感图像(Remote Sensing Image)](#RSI)

### [13. GAN/生成式/对抗式(GAN/Generative/Adversarial)](#GAN)

### [14. 图像生成/图像合成(Image Generation/Image Synthesis)](#IGIS)

### [15. 场景图(Scene Graph](#SG)

* [场景图生成(Scene Graph Generation)](#SGG)
* [场景图预测(Scene Graph Prediction)](#SGP)
* [场景图理解(Scene Graph Understanding)](#SGU)

### [16. 视觉定位/位姿估计(Visual Localization/Pose Estimation)](#VisualLocalization)

### [17. 视觉推理/视觉问答(Visual Reasoning/VQA)](#VisualReasoning)

### [18. 视觉预测(Vision-based Prediction)](#Vision-basedPrediction)

### [19. 神经网络结构设计(Neural Network Structure Design)](#NNS)

* [CNN](#CNN)
* [Transformer](#Transformer)
* [图神经网络(GNN)](#GNN)
* [神经网络架构搜索(NAS)](#NAS)
* [MLP](#MLP)

### [20. 神经网络可解释性(Neural Network Interpretability)](#interpretability)

### [21. 数据集(Dataset)](#Dataset)

### [22. 数据处理(Data Processing)](#DataProcessing)

* [数据增广(Data Augmentation)](#DataAugmentation)
* [归一化/正则化(Batch Normalization)](#BatchNormalization)
* [图像聚类(Image Clustering)](#ImageClustering)
* [图像压缩(Image Compression)](#ImageCompression)

### [23. 图像特征提取与匹配(Image feature extraction and matching)](#matching)

### [24. 视觉表征学习(Visual Representation Learning)](#VisualRL)

### [25. 模型训练/泛化(Model Training/Generalization)](#ModelTraining)

* [噪声标签(Noisy Label)](#NoisyLabel)
* [长尾分布(Long-Tailed Distribution)](#Long-Tailed)

### [26. 模型压缩(Model Compression)](#ModelCompression)

* [知识蒸馏(Knowledge Distillation)](#KnowledgeDistillation)
* [剪枝(Pruning)](#Pruning)
* [量化(Quantization)](#Quantization)

### [27. 模型评估(Model Evaluation)](#ModelEvaluation)

### [28. 图像分类(Image Classification)](#ImageClassification)

### [29. 图像计数(Image Counting)](#CrowdCounting)

### [30. 机器人(Robotic)](#Robotic)

### [31. 半监督学习/弱监督学习/无监督学习/自监督学习(Self-supervised Learning/Semi-supervised Learning)](#self-supervisedlearning)

### [32. 多模态学习(Multi-Modal Learning)](#MMLearning)

* [视听学习(Audio-visual Learning)](#Audio-VisualLearning)
* [视觉-语言（Vision-language）](#VLRL)

### [33. 主动学习(Active Learning)](#ActiveLearning)

### [34. 小样本学习/零样本学习(Few-shot/Zero-shot Learning)](#Few-shotLearning)

### [35. 持续学习(Continual Learning/Life-long Learning)](#ContinualLearning)

### [36. 迁移学习/domain/自适应(Transfer Learning/Domain Adaptation)](#domain)

### [37. 度量学习(Metric Learning)](#MetricLearning)

### [38. 对比学习(Contrastive Learning)](#ContrastiveLearning)

### [39. 增量学习(Incremental Learning)](#IncrementalLearning)

### [40. 强化学习(Reinforcement Learning)](#RL)

### [41. 元学习(Meta Learning)](#MetaLearning)

### [42. 联邦学习(Federated Learning](#federatedlearning)

### [43. 自动驾驶(Federated Learning](#automatic driving)




### [其他](#100)



<br><br>

<a name="detection"/> 

## 检测



<br>

<a name="IOD"/> 

### 2D目标检测(2D Object Detection)

[3]Enhanced Training of Query-Based Object Detection via Selective Query Recollection<br>
[paper](https://arxiv.org/abs/2212.07593) | [code](https://github.com/Fangyi-Chen/SQR)<br><br>

[2]DETRs with Hybrid Matching<br>
[paper](https://arxiv.org/abs/2207.13080) | [code](https://github.com/HDETR)<br><br>

[1]YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors(YOLOv7)<br>
[paper](https://arxiv.org/abs/2207.02696) | [code](https://github.com/WongKinYiu/yolov7)<br><br>

<br>

<br>


<a name="VOD"/> 

### 视频目标检测(Video Object Detection)

[1]SCOTCH and SODA: A Transformer Video Shadow Detection Framework<br>
[paper](https://arxiv.org/abs/2211.06885) <br><br>

<br>

<br>

<a name="3DOD"/> 

### 3D目标检测(3D object detection)

[1]ConQueR: Query Contrast Voxel-DETR for 3D Object Detection(3D 目标检测的Query Contrast Voxel-DETR)
[paper](https://arxiv.org/abs/2212.07289) | [code](https://github.com/poodarchu/ConQueR)<br><br>

<br>

<br>

<a name="HOI"/> 

### 人物交互检测(HOI Detection)

<br>

<br>

<a name="COD"/> 

### 伪装目标检测(Camouflaged Object Detection)

<br>

<br>

<a name="ROD"/> 

### 旋转目标检测(Rotation Object Detection)

<br>

<a name="SOD"/> 

### 显著性目标检测(Saliency Object Detection)

<br>


<br>

<a name="KeypointDetection"/> 

### 关键点检测(Keypoint Detection)

<br>

<br>

<a name="LaneDetection"/> 

### 车道线检测(Lane Detection)

<br>

<br>

<a name="EdgeDetection"/> 

### 边缘检测(Edge Detection)

<br>

<br>

<a name="VPD"/> 

### 消失点检测(Vanishing Point Detection)

<br>

<br>

<a name="AnomalyDetection"/> 

### 异常检测(Anomaly Detection)

[2]Lossy Compression for Robust Unsupervised Time-Series Anomaly Detection<br>
[paper](https://arxiv.org/abs/2212.02303) <br><br>

[1]Multimodal Industrial Anomaly Detection via Hybrid Fusion<br>
[paper](https://arxiv.org/abs/2303.00601) | [code](https://github.com/nomewang/M3DM)<br><br>

<br>


<br>

<a name="Segmentation"/> 


## 分割(Segmentation)

<br>

<a name="ImageSegmentation"/> 

### 图像分割(Image Segmentation)

<br>

<br>

<a name="PanopticSegmentation"/> 

### 全景分割(Panoptic Segmentation)

<br>

<br>

<a name="SemanticSegmentation"/> 

### 语义分割(Semantic Segmentation)

[1]Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation<br>
[paper](https://arxiv.org/abs/2302.14250) <br><br>

<br>

<br>

<a name="InstanceSegmentation"/> 

### 实例分割(Instance Segmentation)

[2]ISBNet: a 3D Point Cloud Instance Segmentation Network with Instance-aware Sampling and Box-aware Dynamic Convolution<br>
[paper](https://arxiv.org/abs/2303.00246)<br><br>

[1]PolyFormer: Referring Image Segmentation as Sequential Polygon Generation(PolyFormer：将图像分割表述为顺序多边形生成)<br>
[paper](https://arxiv.org/abs/2302.07387) <br><br>

<br>

<br>

<a name="Superpixel"/> 

### 超像素(Superpixel)

<br>

<a name="VOS"/> 

### 视频目标分割(Video Object Segmentation)

<br>

<br>

<a name="Matting"/> 

### 抠图(Matting)

<br>

<a name="DensePrediction"/> 

### 密集预测(Dense Prediction)

<br>

<br>

<a name="VideoProcessing"/> 

## 视频处理(Video Processing)

<br>

<br>

<a name="VideoEditing"/> 

### 视频编辑(Video Editing)

[1]Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation<br>
[paper](https://arxiv.org/abs/2303.00440) | [code](https://github.com/MCG-NJU/EMA-VFI)<br><br>

<br>

<br>

<a name="VideoGeneration"/> 

### 视频生成/视频合成(Video Generation/Video Synthesis)

[1]Video Probabilistic Diffusion Models in Projected Latent Space(投影潜在空间中的视频概率扩散模型)<br>
[paper](https://arxiv.org/abs/2302.07685) | [project](https://sihyun.me/PVDM)<br><br>


<br>

<br>

<a name="VideoSR"/> 

### 视频超分(Video Super-Resolution)

<br>

<br>

<a name="Estimation"/> 

## 估计(Estimation)


<br>

<a name="Flow/Pose/MotionEstimation"/> 

### 光流/运动估计(Optical Flow/Motion Estimation)

<br>

<br>

<a name="DepthEstimation"/> 

### 深度估计(Depth Estimation)

<br>


<br>

<a name="HumanPoseEstimation"/> 

### 人体解析/人体姿态估计(Human Parsing/Human Pose Estimation)

[1]Relightable Neural Human Assets from Multi-view Gradient Illuminations(来自多视图渐变照明的可照明神经人类资产)<br>
[paper](https://arxiv.org/abs/2212.07648)<br><br>

<br>

<br>

<a name="GestureEstimation"/> 

### 手势估计(Gesture Estimation)

<br>


<br>

<a name="ImageProcessing"/> 


## 图像处理(Image Processing)

<br>

<a name="SuperResolution"/> 

### 超分辨率(Super Resolution)

[1]Denoising Diffusion Probabilistic Models for Robust Image Super-Resolution in the Wild(野外鲁棒图像超分辨率的去噪扩散概率模型)<br>
[paper](https://arxiv.org/abs/2302.07864) | [project](https://sihyun.me/PVDM/)<br><br>

<br>

<br>

<a name="ImageRestoration"/> 

###  图像复原/图像增强/图像重建(Image Restoration/Image Reconstruction)

[1]Robust Unsupervised StyleGAN Image Restoration<br>
[paper](https://arxiv.org/abs/2302.06733)<br><br>

[5]Raw Image Reconstruction with Learned Compact Metadata<br>
[paper](https://arxiv.org/abs/2302.12995)<br><br>

[4]Efficient and Explicit Modelling of Image Hierarchies for Image Restoration<br>
[paper](https://arxiv.org/abs/2303.00748) | [code](https://github.com/ofsoundof/GRL-Image-Restoration)<br><br>

[3]Imagic: Text-Based Real Image Editing with Diffusion Models<br>
[paper](https://arxiv.org/abs/2210.09276) | [project](https://imagic-editing.github.io/)<br><br>

[2]High-resolution image reconstruction with latent diffusion models from human brain activity<br>
[paper](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2) | [project](https://sites.google.com/view/stablediffusion-with-brain/)<br><br>

[1]Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models<br>
[paper](https://arxiv.org/abs/2211.10655)<br><br>

<br>

<br>


<a name="ISR"/> 

### 图像去阴影/去反射(Image Shadow Removal/Image Reflection Removal)

<br>



<a name="ImageDenoising"/> 

### 图像去噪/去模糊/去雨去雾(Image Denoising)

<br>

<br>

<a name="ImageEdit"/> 

### 图像编辑/图像修复(Image Edit/Inpainting)

<br>

<br>

<a name="ImageTranslation"/> 

### 图像翻译(Image Translation)

<br>

<br>

<a name="IQA"/> 

### 图像质量评估(Image Quality Assessment)

[1]Quality-aware Pre-trained Models for Blind Image Quality Assessment<br>
[paper](https://arxiv.org/abs/2303.00521)<br><br>

<br>

<a name="StyleTransfer"/> 

### 风格迁移(Style Transfer)

<br>


<br>

<a name="Face"/> 

## 人脸(Face)

<br>

<br>

<a name="FacialRecognition"/> 

### 人脸识别/检测(Facial Recognition/Detection)

<br>

<br>

<a name="FaceSynthesis"/> 

### 人脸生成/合成/重建/编辑(Face Generation/Face Synthesis/Face Reconstruction/Face Editing)
[1]MetaPortrait: Identity-Preserving Talking Head Generation with Fast Personalized Adaptation(MetaPortrait：具有快速个性化适应的身份保持谈话头像生成)<br>
[paper](https://arxiv.org/abs/2212.08062) | [code](https://github.com/Meta-Portrait/MetaPortrait)<br><br>

<br>

<br>

<a name="FaceAnti-Spoofing"/> 

### 人脸伪造/反欺骗(Face Forgery/Face Anti-Spoofing)

<br>


<br>

<a name="ObjectTracking"/> 

## 目标跟踪(Object Tracking)

[1]Simple Cues Lead to a Strong Multi-Object Tracker<br>
[paper](https://arxiv.org/abs/2206.04656)<br><br>

<br>

<br>
<a name="ImageRetrieval"/> 

## 图像&视频检索/视频理解(Image&Video Retrieval/Video Understanding)

<br>



<a name="ActionRecognition"/> 

### 行为识别/动作识别/检测/分割/定位(Action/Activity Recognition)

<br>

<a name="Re-Identification"/> 

### 行人重识别/检测(Re-Identification/Detection)

<br>

<a name="VideoCaption"/> 

### 图像/视频字幕(Image/Video Caption)

[1]Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning<br>
[paper](https://arxiv.org/abs/2302.14115) | [code](https://antoyang.github.io/vid2seq.html)<br><br>

<br>


<a name="MedicalImaging"/> 

## 医学影像(Medical Imaging)

<br>


<a name="TDR"/> 


## 文本检测/识别/理解(Text Detection/Recognition/Understanding)

<br>



<a name="RSI"/> 

## 遥感图像(Remote Sensing Image)

<br>


<a name="GAN"/> 

## GAN/生成式/对抗式(GAN/Generative/Adversarial)

[2]T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete Representations<br>
[paper](https://arxiv.org/abs/2301.06052) | [project](https://mael-zys.github.io/T2M-GPT/)<br><br>

[1]Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars<br>
[paper](https://arxiv.org/abs/2211.11208) | [project](https://mrtornado24.github.io/Next3D/)<br><br>


<br>

<a name="IGIS"/> 

## 图像生成/图像合成(Image Generation/Image Synthesis)

[3]Person Image Synthesis via Denoising Diffusion Model<br>
[paper](https://arxiv.org/abs/2211.12500) <br><br>

[2]Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models(使用预训练的 2D 扩散模型解决 3D 逆问题)<br>
[paper](https://arxiv.org/abs/2211.10655) <br><br>

[1]Parallel Diffusion Models of Operator and Image for Blind Inverse Problems(盲反问题算子和图像的并行扩散模型)<br>
[paper](https://arxiv.org/abs/2211.10656) <br><br>

<br>

<a name="3DVision"/> 

## 三维视觉(3D Vision)

<br>

<a name="3DPC"/> 

### 点云(Point Cloud)

[1]Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting<br>
[paper](https://arxiv.org/abs/2302.13130) | [code](https://github.com/tarashakhurana/4d-occ-forecasting)<br><br>

<br>


<a name="3DReconstruction"/> 

### 三维重建(3D Reconstruction)

[3]Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes<br>
[paper](https://arxiv.org/abs/2302.14348) | [code](https://github.com/jyunlee/Im2Hands)<br><br>

[2]ECON: Explicit Clothed humans Obtained from Normals<br>
[paper](https://arxiv.org/abs/2212.07422) | [code](https://github.com/YuliangXiu/ECON)<br><br>

[1]Structured 3D Features for Reconstructing Relightable and Animatable Avatars<br>
[paper](https://arxiv.org/abs/2212.06820) | [project](https://enriccorona.github.io/s3f/)<br><br>

<br>

<a name="NeRF"/> 

### 场景重建/视图合成/新视角合成(Novel View Synthesis)

[5]NeRF-Gaze: A Head-Eye Redirection Parametric Model for Gaze Estimation<br>
[paper](https://arxiv.org/abs/2212.14710) <br><br>

[4]Renderable Neural Radiance Map for Visual Navigation<br>
[paper](https://arxiv.org/abs/2303.00304)<br><br>

[3]Real-Time Neural Light Field on Mobile Devices<br>
[paper](https://arxiv.org/abs/2212.08057) | [project](https://snap-research.github.io/MobileR2L/)<br><br>

[2]Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures<br>
[paper](https://arxiv.org/abs/2211.07600) | [code](https://github.com/eladrich/latent-nerf)<br><br>

[1]NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior<br>
[paper](https://arxiv.org/abs/2212.07388) | [project](https://nope-nerf.active.vision/)<br><br>

<br>

<a name="ModelCompression"/> 

## 模型压缩(Model Compression)

<br>

<a name="KnowledgeDistillation"/> 

### 知识蒸馏(Knowledge Distillation)

[3]Learning to Retain while Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation<br>
[paper](https://arxiv.org/abs/2302.14290) <br><br>

[2]Generic-to-Specific Distillation of Masked Autoencoders<br>
[paper](https://arxiv.org/abs/2302.14771) | [code](https://github.com/pengzhiliang/G2SD)<br><br>

[1]CLIPPING: Distilling CLIP-based Models for Video-Language Understanding(CLIPPING：为视频语言理解提炼基于 CLIP 的模型)<br>
[paper](https://openreview.net/forum?id=aqIvCsRsYt) <br><br>

<br>

<a name="Pruning"/> 

### 剪枝(Pruning)

<br>

<a name="Quantization"/> 

### 量化(Quantization)



<br>

<a name="NNS"/> 

## 神经网络结构设计(Neural Network Structure Design)



<br>

<a name="CNN"/> 

### CNN

[2]Demystify Transformers & Convolutions in Modern Image Deep Networks<br>
[paper](https://arxiv.org/abs/2211.05781) | [code](https://github.com/OpenGVLab/STM-Evaluation)<br><br>

[1]InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions<br>
[paper](https://arxiv.org/abs/2211.05778) | [code](https://github.com/OpenGVLab/InternImage)<br><br>


<br>

<a name="Transformer"/> 

### Transformer

[1]Integrally Pre-Trained Transformer Pyramid Networks<br>
[paper](https://arxiv.org/abs/2211.12735) | [code](https://github.com/sunsmarterjie/iTPN)<br><br>

<br>

<a name="GNN"/> 

### 图神经网络(GNN)



<br>

<a name="NAS"/> 

### 神经网络架构搜索(NAS)

[2]PA&DA: Jointly Sampling PAth and DAta for Consistent NAS<br>
[paper](https://arxiv.org/abs/2302.14772) | [code](https://github.com/ShunLu91/PA-DA)<br><br>

[1]Stitchable Neural Networks(可缝合神经网络)<br>
[paper](https://arxiv.org/abs/2302.06586) | [code](https://github.com/ziplab/SN-Net)<br><br>

<br>

<a name="MLP"/> 

### MLP


<br>

<a name="M AE"/> 

### MAE

[1]Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders
[paper](https://arxiv.org/abs/2212.06785) | [code](https://github.com/ZrrSkywalker/I2P-MAE)<br><br>



<br>

<a name="DataProcessing"/> 

## 数据处理(Data Processing)

<br>

<a name="DataAugmentation"/> 

### 数据增广(Data Augmentation)





<br>

<a name="BatchNormalization"/> 

### 归一化/正则化(Batch Normalization)



<br>

<a name="ImageClustering"/> 

### 图像聚类(Image Clustering)



<br>


<a name="ImageCompression"/> 

### 图像压缩(Image Compression)



<br>

<a name="ModelTraining"/> 

## 模型训练/泛化(Model Training/Generalization)

[1]DART: Diversify-Aggregate-Repeat Training Improves Generalization of Neural Networks<br>
[paper](https://arxiv.org/abs/2302.14685)<br><br>

<br>

<a name="NoisyLabel"/> 

### 噪声标签(Noisy Label)

[1]Combating noisy labels in object detection datasets<br>
[paper](https://arxiv.org/abs/2211.13993)<br><br>



<br>

<a name="Long-Tailed"/> 

### 长尾分布(Long-Tailed Distribution)




<br>

<a name="matching"/> 


## 图像特征提取与匹配(Image feature extraction and matching)



<br>

<a name="VisualRL"/> 

## 视觉表征学习(Visual Representation Learning)



<br>

<a name="ModelEvaluation"/> 

## 模型评估(Model Evaluation)



<br>

<a name="MMLearning"/> 

## 多模态学习(Multi-Modal Learning)

[2]Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information(通过最大化多模态互信息实现一体化预训练)<br>
[paper](https://arxiv.org/abs/2211.09807) | [code](https://github.com/OpenGVLab/M3I-Pretraining)<br><br>

[1]Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks(Uni-Perceiver v2：用于大规模视觉和视觉语言任务的通才模型)<br>
[paper](https://arxiv.org/abs/2211.09808) | [code](https://github.com/fundamentalvision/Uni-Perceiver)<br><br>


<br>

<a name="Audio-VisualLearning"/> 

### 视听学习(Audio-visual Learning)




<br>

<a name="VLRL"/> 

### 视觉-语言（Vision-language）

[1]Turning a CLIP Model into a Scene Text Detector<br>
[paper](https://arxiv.org/abs/2302.14338) | [code](https://github.com/wenwenyu/TCM)<br><br>

[1]GIVL: Improving Geographical Inclusivity of Vision-Language Models with Pre-Training Methods<br>
[paper](https://arxiv.org/abs/2301.01893) <br><br>


<br>
<a name="Vision-basedPrediction"/> 

## 视觉预测(Vision-based Prediction)

[3]Intention-Conditioned Long-Term Human Egocentric Action Forecasting<br>
[paper](https://arxiv.org/abs/2207.12080) | [code](https://github.com/Evm7/ego4dlta-icvae)<br><br>

[2]Computational Choreography using Human Motion Synthesis<br>
[paper](https://arxiv.org/abs/2210.04366) <br><br>

[1]IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-Agent Trajectory Prediction<br>
[paper](https://arxiv.org/abs/2303.00575) <br><br>



<br>
<a name="Dataset"/> 

## 数据集(Dataset)



<br>

<a name="ActiveLearning"/> 

## 主动学习(Active Learning)



<br>

<a name="Few-shotLearning"/> 

## 小样本学习/零样本学习(Few-shot Learning/Zero-shot Learning)



<br>

<a name="ContinualLearning"/> 

## 持续学习(Continual Learning/Life-long Learning)



<br>

<a name="SG"/> 

## 场景图(Scene Graph)

<br>

<a name="SGG"/> 

### 场景图生成(Scene Graph Generation)



<br>

<a name="SGP"/> 

### 场景图预测(Scene Graph Prediction)

<br>

<a name="SGU"/> 

### 场景图理解(Scene Graph Understanding)

<br>

<a name="VisualLocalization"/> 

## 视觉定位/位姿估计(Visual Localization/Pose Estimation)



<br>

<a name="VisualReasoning"/> 

## 视觉推理/视觉问答(Visual Reasoning/VQA)



<br>

<a name="ImageClassification"/> 

## 图像分类(Image Classification)
[1]I2MVFormer: Large Language Model Generated Multi-View Document Supervision for Zero-Shot Image Classification(I2MVFormer：用于零样本图像分类的大型语言模型生成的多视图文档监督)<br>
[paper](https://arxiv.org/abs/2212.02291)<br><br>

<br>

<a name="domain"/> 

## 迁移学习/domain/自适应(Transfer Learning/Domain Adaptation)



<br>

<a name="MetricLearning"/> 

## 度量学习(Metric Learning)



<br>

<a name="ContrastiveLearning"/> 

## 对比学习(Contrastive Learning)



<br>

<a name="IncrementalLearning"/> 

## 增量学习(Incremental Learning)



<br>

<a name="RL"/> 

## 强化学习(Reinforcement Learning)



<br>

<a name="MetaLearning"/> 

## 元学习(Meta Learning)



<br>

<a name="Robotic"/> 

## 机器人(Robotic)

[1]PyPose: A Library for Robot Learning with Physics-based Optimization(PyPose：基于物理优化的机器人学习库)<br>
[paper](https://arxiv.org/abs/2209.15428) | [code](https://pypose.org/)<br><br>


<br>

<a name="self-supervisedlearning"/> 

## 半监督学习/弱监督学习/无监督学习/自监督学习(Self-supervised Learning/Semi-supervised Learning)

[2]Siamese Image Modeling for Self-Supervised Vision Representation Learning<br>
[paper](https://arxiv.org/abs/2206.01204) | [code](https://github.com/fundamentalvision/Siamese-Image-Modeling)<br><br>

[1]Cut and Learn for Unsupervised Object Detection and Instance Segmentation<br>
[paper](https://arxiv.org/abs/2301.11320) | [project](http://people.eecs.berkeley.edu/~xdwang/projects/CutLER/)<br><br>

<br>

<a name="interpretability"/> 

## 神经网络可解释性(Neural Network Interpretability)

[1]SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundaries(SplineCam：深度网络几何和决策边界的精确可视化和表征)<br>
[paper](https://arxiv.org/abs/2302.12828) | [code](https://github.com/AhmedImtiazPrio/SplineCAM)<br><br>

<br>

<a name="CrowdCounting"/> 


## 图像计数(Image Counting)



<br>

<a name="federatedlearning"/> 


## 联邦学习(Federated Learning)


<br>

<a name="automatic driving"/> 


## 自动驾驶(automatic driving)


[1]BEVFormer v2: Adapting Modern Image Backbones to Bird’s-Eye-View Recognition via Perspective Supervision(BEVFormer v2：通过透视监督使现代图像主干适应鸟瞰图识别)<br>
[paper](https://arxiv.org/abs/2211.10439)<br><br>

<br>

<a name="100"/> 

## 其他

[6]Physical-World Optical Adversarial Attacks on 3D Face Recognition<br>
[paper](https://arxiv.org/abs/2205.13412) <br><br>

[5]Improving Cross-Modal Retrieval with Set of Diverse Embeddings<br>
[paper](https://arxiv.org/abs/2211.16761) <br><br>

[4]Neural Video Compression with Diverse Contexts<br>
[paper](https://arxiv.org/abs/2302.14402) | [code](https://github.com/microsoft/DCVC)<br><br>

[3]Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger<br>
[paper](https://arxiv.org/abs/2302.14677) <br><br>

[2]Single Image Backdoor Inversion via Robust Smoothed Classifiers<br>
[paper](https://arxiv.org/abs/2303.00215) | [code](https://github.com/locuslab/smoothinv)<br><br>

[1]Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision<br>
[paper](https://arxiv.org/abs/2303.00462) | [code](https://github.com/Toytiny/CMFlow)<br><br>

<br>

<br>

<a name="2"/> 


# 2. CVPR2023 Oral

<br>

<a name="3"/> 

# 3. CVPR2023 论文解读汇总


<br>



<br>

<a name="4"/> 

# 4. CVPR2023论文分享

<br>

<br>

<a name="5"/> 

# 5. To do list

* CVPR2023 Workshop
